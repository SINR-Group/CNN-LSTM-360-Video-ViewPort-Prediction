{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saliency and motion videos and split them into chunks\n",
    "split = 5 # split the video every five seconds\n",
    "path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitVideo(videos, split, tp):\n",
    "    newdir = path+'datasets/content/'+tp+'splitby-'+str(split)+'-seconds'\n",
    "    if os.path.exists(newdir):\n",
    "        os.system('rm -rf '+newdir)\n",
    "    os.makedirs(newdir)\n",
    "    for video in videos:\n",
    "        command = 'ffmpeg -i ../datasets/content/'+tp+'/'+video+' -reset_timestamps 1 -map 0 -segment_time '+str(split)+' -f segment '+newdir+'/'+video[:-4]+'%03d.mp4'\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImages(videos, split, tp):\n",
    "    newdir = path+'datasets/content/'+tp+'splitby-'+str(split)+'-seconds'\n",
    "    if os.path.exists(newdir):\n",
    "        os.system('rm -rf '+newdir)\n",
    "    os.makedirs(newdir)\n",
    "    for video in videos:\n",
    "        os.system('ffmpeg -i ../datasets/content/'+tp+'/'+video+' -vf fps=30 '+newdir+'/'+video[:-4]+'%d.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliVideos = os.listdir(path+'datasets/content/saliency/')\n",
    "motionVideos = os.listdir(path+'datasets/content/motion/')\n",
    "\n",
    "extractImages(saliVideos, split, 'saliency')\n",
    "extractImages(motionVideos, split, 'motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make both saliency and motion map videos as numpy arrays\n",
    "def makeVideoNumpy(videos, split, tp):\n",
    "    fps = 30\n",
    "    totalFrames = 1800\n",
    "    imagesToRead = fps*split # total images to read based on split\n",
    "    newdir = path+'datasets/content/'+tp+'Images'\n",
    "    for video in videos:\n",
    "        count = 1\n",
    "        for i in range(1, totalFrames+1, imagesToRead):\n",
    "            npArray = newdir+'/'+video[:-4]+str(count)+'.npy'\n",
    "            count += 1\n",
    "            tempArray = []\n",
    "            for j in range(imagesToRead):\n",
    "                imageName = newdir+'/'+video[:-4]+str(i+j)+'.png'\n",
    "                image = cv2.imread(imageName, 0)\n",
    "                tempArray.append(image)\n",
    "            #print(np.array(tempArray).shape)\n",
    "            np.save(npArray, np.array(tempArray))\n",
    "makeVideoNumpy(saliVideos, split, 'saliency')\n",
    "makeVideoNumpy(motionVideos, split, 'motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tiles information as numpy arrays\n",
    "def makeTilesNumpyBackup(videosTileData, split):\n",
    "    files = glob.glob('../datasets/sensory/tile/*01*.csv')\n",
    "    files = sorted(files)[5:]\n",
    "    fps = 30\n",
    "    totalFrames = 1800\n",
    "    imagesToRead = fps*split # total images to read based on split\n",
    "    for video, f in zip(videosTileData, files):\n",
    "        count = 1\n",
    "        for i in range(1, totalFrames+1, imagesToRead):\n",
    "            npArray = f[:-8]+str(count)+'_split_by_'+str(split)+'_seconds.npy'\n",
    "            tempArray = []\n",
    "            for j in range(imagesToRead):\n",
    "                tempArray.append(video[i+j-1])\n",
    "            #print(np.array(tempArray).shape)\n",
    "            np.save(npArray, np.array(tempArray))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tiles information as numpy arrays\n",
    "def makeTilesNumpy(video, f, split):\n",
    "    fps = 30\n",
    "    totalFrames = 1800\n",
    "    imagesToRead = fps*split # total images to read based on split\n",
    "    count = 1\n",
    "    for i in range(1, totalFrames+1, imagesToRead):\n",
    "        npArray = f[:-8]+str(count)+'_split_by_'+str(split)+'_seconds.npy'\n",
    "        tempArray = []\n",
    "        for j in range(imagesToRead):\n",
    "            tempArray.append(video[i+j-1])\n",
    "        print(np.array(tempArray).shape)\n",
    "        np.save(npArray, np.array(tempArray))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n",
      "(150, 1920, 3840)\n"
     ]
    }
   ],
   "source": [
    "# encode tile information into images in banary fashion for convenience\n",
    "def encodeTileInfoToImages():\n",
    "    files = glob.glob('../datasets/sensory/tile/*01*.csv')\n",
    "    files = sorted(files)[5:]\n",
    "    for f in files:\n",
    "        width = 3840\n",
    "        breadth = 1920\n",
    "        tileSize = 192\n",
    "        frames = []\n",
    "        tilesInColumn = width / tileSize\n",
    "        lines = open(f, 'r')\n",
    "        lines = lines.readlines()[1:]\n",
    "        tilesInFrames = []\n",
    "        for line in lines:\n",
    "            line = line.strip().split(',')[1:]\n",
    "            line = [int(i) for i in line]\n",
    "            tilesInFrames.append(line)\n",
    "        for i, tiles in enumerate(tilesInFrames):\n",
    "            frame = np.zeros(width*breadth, dtype=bool)\n",
    "            for tileNo in tiles:\n",
    "                tileRowNumber = int((tileNo - 1) / tilesInColumn)\n",
    "                tileColumnNumber = (tileNo - 1) % tilesInColumn\n",
    "                firstPixel = tileRowNumber * width * tileSize + tileColumnNumber * tileSize\n",
    "                for rowPixel in range(0, tileSize):\n",
    "                    for columnPixel in range(0, tileSize):\n",
    "                        frame[int(firstPixel + rowPixel * width + columnPixel)] = 1\n",
    "            frame = frame.reshape((1920, 3840))\n",
    "            frames.append(frame)\n",
    "        makeTilesNumpy(frames, f, split)\n",
    "        frames = None\n",
    "encodeTileInfoToImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1920, 3840)\n"
     ]
    }
   ],
   "source": [
    "p ='../datasets/content/saliencyImages/landscape_saliency1.npy'\n",
    "data = np.load(p)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255. 255. 255. ...   0.   0.   0.]\n",
      " [255. 255. 255. ...   0.   0.   0.]\n",
      " [255. 255. 255. ...   0.   0.   0.]\n",
      " ...\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "width = 512\n",
    "breadth = 512\n",
    "tiles = [1, 14, 19, 12]\n",
    "tileSize = 64\n",
    "frame = np.zeros(width * breadth)\n",
    "tilesInColumn = width / tileSize\n",
    "\n",
    "for tileNo in tiles:\n",
    "    tileRowNumber = int((tileNo - 1) / tilesInColumn)\n",
    "    tileColumnNumber = (tileNo - 1) % tilesInColumn\n",
    "    firstPixel = tileRowNumber * width * tileSize + tileColumnNumber * tileSize\n",
    "    for rowPixel in range(0, tileSize):\n",
    "        for columnPixel in range(0, tileSize):\n",
    "            frame[int(firstPixel + rowPixel * width + columnPixel)] = 255\n",
    "frame = np.reshape(frame, (breadth, width))width*\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(frame, interpolation='nearest')\n",
    "plt.savefig('sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
