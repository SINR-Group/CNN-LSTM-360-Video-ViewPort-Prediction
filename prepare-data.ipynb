{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saliency and motion videos and split them into chunks\n",
    "split = 5 # split the video every five seconds\n",
    "path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitVideo(videos, split, tp):\n",
    "    newdir = path+'datasets/content/'+tp+'splitby-'+str(split)+'-seconds'\n",
    "    if os.path.exists(newdir):\n",
    "        os.system('rm -rf '+newdir)\n",
    "    os.makedirs(newdir)\n",
    "    for video in videos:\n",
    "        command = 'ffmpeg -i ../datasets/content/'+tp+'/'+video+' -reset_timestamps 1 -map 0 -segment_time '+str(split)+' -f segment '+newdir+'/'+video[:-4]+'%03d.mp4'\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImages(videos, split, tp):\n",
    "    newdir = path+'datasets/content/'+tp+'splitby-'+str(split)+'-seconds'\n",
    "    if os.path.exists(newdir):\n",
    "        os.system('rm -rf '+newdir)\n",
    "    os.makedirs(newdir)\n",
    "    for video in videos:\n",
    "        os.system('ffmpeg -i ../datasets/content/'+tp+'/'+video+' -vf fps=30 '+newdir+'/'+video[:-4]+'%d.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliVideos = os.listdir(path+'datasets/content/saliency/')\n",
    "motionVideos = os.listdir(path+'datasets/content/motion/')\n",
    "\n",
    "extractImages(saliVideos, split, 'saliency')\n",
    "extractImages(motionVideos, split, 'motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make both saliency and motion map videos as numpy arrays\n",
    "def makeVideoNumpy(videos, split, tp):\n",
    "    fps = 30\n",
    "    totalFrames = 1800\n",
    "    imagesToRead = fps*split # total images to read based on split\n",
    "    newdir = path+'datasets/content/'+tp+'Images'\n",
    "    for video in videos:\n",
    "        count = 1\n",
    "        for i in range(1, totalFrames+1, imagesToRead):\n",
    "            npArray = newdir+'/'+video[:-4]+str(count)+'.npy'\n",
    "            count += 1\n",
    "            tempArray = []\n",
    "            for j in range(imagesToRead):\n",
    "                imageName = newdir+'/'+video[:-4]+str(i+j)+'.png'\n",
    "                image = cv2.imread(imageName, 0)\n",
    "                tempArray.append(image)\n",
    "            #print(np.array(tempArray).shape)\n",
    "            np.save(npArray, np.array(tempArray))\n",
    "makeVideoNumpy(saliVideos, split, 'saliency')\n",
    "makeVideoNumpy(motionVideos, split, 'motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tiles information as numpy arrays\n",
    "def makeTilesNumpy(videosTileData, split):\n",
    "    files = glob.glob('../datasets/sensory/tile/*01*.csv')\n",
    "    fps = 30\n",
    "    totalFrames = 1800\n",
    "    imagesToRead = fps*split # total images to read based on split\n",
    "    for video, f in zip(videosTileData, files):\n",
    "        count = 1\n",
    "        for i in range(1, totalFrames+1, imagesToRead):\n",
    "            npArray = f[:-8]+str(count)+'_split_by_'+str(split)+'_seconds.npy'\n",
    "            tempArray = []\n",
    "            for j in range(imagesToRead):\n",
    "                tempArray.append(video[i+j-1])\n",
    "            #print(np.array(tempArray).shape)\n",
    "            np.save(npArray, np.array(tempArray))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode tile information into images in banary fashion for convenience\n",
    "def encodeTileInfoToImages():\n",
    "    files = glob.glob('../datasets/sensory/tile/*01*.csv')\n",
    "    tileData = []\n",
    "    for f in files:\n",
    "        headData = np.zeros((1800, 200))\n",
    "        lines = open(f, 'r')\n",
    "        lines = lines.readlines()[1:]\n",
    "        tiles = []\n",
    "        for line in lines:\n",
    "            line = line.strip().split(',')[1:]\n",
    "            line = [int(i) for i in line]\n",
    "            tiles.append(line)\n",
    "        for i, tile in enumerate(tiles):\n",
    "            for j in tile:\n",
    "                headData[i][j-1] = 255\n",
    "        tileData.append(headData)\n",
    "    return tileData\n",
    "tileData = encodeTileInfoToImages()\n",
    "makeTilesNumpy(tileData, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
