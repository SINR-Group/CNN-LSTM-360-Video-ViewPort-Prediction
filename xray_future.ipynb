{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranjal/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "#from data_handler import *\n",
    "import time\n",
    "import scipy\n",
    "from scipy.misc import imread\n",
    "import pylab as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '/home/pranjal/FUTURE_dataset/data64/'\n",
    "#FILEPATH = '/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/FUTURE/data64/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = {}\n",
    "si = 1\n",
    "ei = si+6000\n",
    "\n",
    "for i in range(si, ei):\n",
    "    name = str(i).zfill(4)\n",
    "    foldername = 'sim'+name\n",
    "    files = glob.glob(FILEPATH+foldername+'/scattering/*.npy')\n",
    "    images_list[name] = []\n",
    "    files.sort()\n",
    "        \n",
    "    for f in files:\n",
    "        img = np.load(f)\n",
    "        values = np.sort( img.flatten() )\n",
    "        vmin   = values[ +int( len(values)*0.01 ) ]\n",
    "        idx    = -int( len(values)*0.01 )\n",
    "        if idx >=0:\n",
    "            idx = -1\n",
    "        vmax = values[idx]\n",
    "        img[img > vmax] = vmax\n",
    "        img[img < vmin] = vmin\n",
    "        img = (img-vmin)/(vmax-vmin)\n",
    "        images_list[name].append(img)\n",
    "        #images_list[name].append(imread(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161, 10, 64, 64)\n",
      "(8161, 10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "current = []\n",
    "future  = []\n",
    "names   = []\n",
    "\n",
    "for k in images_list:\n",
    "    if len(images_list[k]) >= 40:\n",
    "        a = np.array(images_list[k][0:10])\n",
    "        b = np.array(images_list[k][10:20])\n",
    "        if len(a.shape) == 3 and len(b.shape) == 3:\n",
    "            current.append(a)\n",
    "            future.append(b)\n",
    "        a = np.array(images_list[k][20:30])\n",
    "        b = np.array(images_list[k][30:40])\n",
    "        if len(a.shape) == 3 and len(b.shape) == 3:\n",
    "            current.append(a)\n",
    "            future.append(b)\n",
    "    elif len(images_list[k]) >= 20:\n",
    "        a = np.array(images_list[k][0:10])\n",
    "        b = np.array(images_list[k][10:20])\n",
    "        if len(a.shape) == 3 and len(b.shape) == 3:\n",
    "            current.append(a)\n",
    "            future.append(b)\n",
    "\n",
    "current = np.array(current)\n",
    "future  = np.array(future)\n",
    "\n",
    "print(current.shape)\n",
    "print(future.shape)\n",
    "\n",
    "# x_test = current\n",
    "# y_test = future\n",
    "\n",
    "x_train = current\n",
    "y_train = future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp length is  1000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e489e8940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode is  ModeResult(mode=array([32]), count=array([20]))\n",
      "2 0\n",
      "91\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#temp = x_train[0][0].flatten()\n",
    "# temp = np.load('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/FUTURE/data64/sim1027/scattering/frame0013.npy')\n",
    "# temp = temp.flatten()\n",
    "# temp = np.sort(temp)\n",
    "\n",
    "#temp = temp[3200:]\n",
    "temp  = max_a\n",
    "print('temp length is ', len(temp))\n",
    "temp = np.sort(temp)\n",
    "temp = temp[:int(len(temp)*0.5)]\n",
    "plt.hist(temp, bins=10)\n",
    "plt.show()\n",
    "\n",
    "print('Mode is ', stats.mode(temp))\n",
    "print(np.min(temp), list(temp).count(0))\n",
    "print(np.max(temp))\n",
    "print(list(temp).count(np.max(temp)))\n",
    "print(list(temp).count(np.max(temp)-1))\n",
    "print(list(temp).count(np.max(temp)-2))\n",
    "print(list(temp).count(np.max(temp)-3))\n",
    "print(list(temp).count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161, 10, 64, 64)\n",
      "(8161, 10, 64, 64)\n",
      "(1750, 10, 64, 64)\n",
      "(1750, 10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161, 10, 4096)\n",
      "(8161, 10, 4096)\n",
      "(1750, 10, 4096)\n",
      "(1750, 10, 4096)\n"
     ]
    }
   ],
   "source": [
    "x_train_flat = x_train.reshape(x_train.shape[0], 10, 4096)\n",
    "y_train_flat = y_train.reshape(x_train.shape[0], 10, 4096)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], 10, 4096)\n",
    "y_test_flat = y_test.reshape(x_test.shape[0], 10, 4096)\n",
    "\n",
    "print(x_train_flat.shape)\n",
    "print(y_train_flat.shape)\n",
    "print(x_test_flat.shape)\n",
    "print(y_test_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 80     # Batch size for training.\n",
    "epochs     = 10     # Number of epochs to train for.\n",
    "latent_dim = 2048   # Latent dimensionality of the encoding space.\n",
    "num_samples = 500   # Number of samples to train on.\n",
    "\n",
    "max_encoder_seq_length = 10\n",
    "max_decoder_seq_length = 10\n",
    "num_encoder_tokens = 4096\n",
    "num_decoder_tokens = 4096\n",
    "input_texts = 1\n",
    "temp_zero   = np.zeros(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161, 10, 4096)\n",
      "(8161, 10, 4096)\n",
      "(8161, 10, 4096)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data  = x_train_flat\n",
    "decoder_target_data = y_train_flat\n",
    "y_train_flat_copy   = y_train_flat.copy()\n",
    "\n",
    "for i in range(len(y_train_flat_copy)):\n",
    "    y_train_flat_copy[i] = np.roll(y_train_flat_copy[i], 1, axis=0)\n",
    "    y_train_flat_copy[i][0] = temp_zero\n",
    "\n",
    "decoder_input_data = y_train_flat_copy\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_target_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred):\n",
    "    mask_true = K.cast(K.not_equal(y_true, y_pred), K.floatx())\n",
    "    masked_squared_error = K.square(mask_true * (y_true - y_pred))\n",
    "    num = K.sum(masked_squared_error, axis=-1)\n",
    "    den = K.sum(mask_true, axis=-1)\n",
    "    masked_mse =  num/den \n",
    "    masked_mse = masked_mse*100\n",
    "    #print(K.eval(den))\n",
    "    return masked_mse\n",
    "    \n",
    "#     all_zero = y_true+y_pred\n",
    "#     non_z = K.count_nonzero(all_zero)\n",
    "#     print(K.int_shape(non_z), K.shape(y_true), K.shape(y_pred))\n",
    "# #     for i, k in enumerate(all_zero):\n",
    "# #         tp = np.count_nonzero(all_zero[i])\n",
    "# #         t.append(tp)\n",
    "#     new_result = K.square(y_pred-y_true)\n",
    "#     for i, k in new_result:\n",
    "#         new_result[i] = new_result[i]/t[i]\n",
    "#     return K.mean(K.square(new_result), axis=-1)\n",
    "    \n",
    "\n",
    "# def dice_coef(y_true, y_pred, smooth, thresh):\n",
    "#     y_pred = y_pred > thresh\n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred_f = K.flatten(y_pred)\n",
    "#     intersection = K.sum(y_true_f * y_pred_f)\n",
    "\n",
    "#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2048) (?, 2048) (?, 2048)\n",
      "(?, ?, 2048)\n",
      "(?, ?, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "print(encoder_outputs.shape, state_h.shape, state_c.shape)\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "print(decoder_outputs.shape)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='relu')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "print(decoder_outputs.shape)\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='adam', loss=my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_33 (InputLayer)            (None, None, 4096)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (None, None, 4096)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                   [(None, 2048), (None, 50339840    input_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                   [(None, None, 2048),  50339840    input_34[0][0]                   \n",
      "                                                                   lstm_27[0][1]                    \n",
      "                                                                   lstm_27[0][2]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, None, 4096)    8392704     lstm_28[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 109,072,384\n",
      "Trainable params: 109,072,384\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "8161/8161 [==============================] - 122s - loss: 0.8060   \n",
      "Epoch 2/60\n",
      "8161/8161 [==============================] - 107s - loss: 0.8071   \n",
      "Epoch 3/60\n",
      "8161/8161 [==============================] - 116s - loss: 0.8044   \n",
      "Epoch 4/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.8053    \n",
      "Epoch 5/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.8011    \n",
      "Epoch 6/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7987    \n",
      "Epoch 7/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7972    \n",
      "Epoch 8/60\n",
      "8161/8161 [==============================] - 105s - loss: 0.7985   \n",
      "Epoch 9/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7975    \n",
      "Epoch 10/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.8010    \n",
      "Epoch 11/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7927    \n",
      "Epoch 12/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7879    \n",
      "Epoch 13/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7923    \n",
      "Epoch 14/60\n",
      "8161/8161 [==============================] - 97s - loss: 0.7914    \n",
      "Epoch 15/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7873    \n",
      "Epoch 16/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7885    \n",
      "Epoch 17/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7830    \n",
      "Epoch 18/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7850    \n",
      "Epoch 19/60\n",
      "8161/8161 [==============================] - 97s - loss: 0.7831    \n",
      "Epoch 20/60\n",
      "8161/8161 [==============================] - 97s - loss: 0.7824    \n",
      "Epoch 21/60\n",
      "8161/8161 [==============================] - 96s - loss: 0.7861    \n",
      "Epoch 22/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7798    \n",
      "Epoch 23/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7760    \n",
      "Epoch 24/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7784    \n",
      "Epoch 25/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7786    \n",
      "Epoch 26/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7765    \n",
      "Epoch 27/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7763    \n",
      "Epoch 28/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7765    \n",
      "Epoch 29/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7667    \n",
      "Epoch 30/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7716    \n",
      "Epoch 31/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7735    \n",
      "Epoch 32/60\n",
      "8161/8161 [==============================] - 101s - loss: 0.7713   \n",
      "Epoch 33/60\n",
      "8161/8161 [==============================] - 104s - loss: 0.7646   \n",
      "Epoch 34/60\n",
      "8161/8161 [==============================] - 102s - loss: 0.7683   \n",
      "Epoch 35/60\n",
      "8161/8161 [==============================] - 106s - loss: 0.7663   \n",
      "Epoch 36/60\n",
      "8161/8161 [==============================] - 99s - loss: 0.7651    \n",
      "Epoch 37/60\n",
      "8161/8161 [==============================] - 98s - loss: 0.7649    \n",
      "Epoch 38/60\n",
      "8161/8161 [==============================] - 98s - loss: 0.7692    \n",
      "Epoch 39/60\n",
      "8161/8161 [==============================] - 108s - loss: 0.7622   \n",
      "Epoch 40/60\n",
      "8161/8161 [==============================] - 105s - loss: 0.7596   \n",
      "Epoch 41/60\n",
      "8161/8161 [==============================] - 136s - loss: 0.7604   \n",
      "Epoch 42/60\n",
      "8161/8161 [==============================] - 127s - loss: 0.7635   \n",
      "Epoch 43/60\n",
      "8161/8161 [==============================] - 108s - loss: 0.7594   \n",
      "Epoch 44/60\n",
      "8161/8161 [==============================] - 97s - loss: 0.7597    \n",
      "Epoch 45/60\n",
      "8161/8161 [==============================] - 104s - loss: 0.7557   \n",
      "Epoch 46/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7568    \n",
      "Epoch 47/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7585    \n",
      "Epoch 48/60\n",
      "8161/8161 [==============================] - 96s - loss: 0.7538    \n",
      "Epoch 49/60\n",
      "8161/8161 [==============================] - 96s - loss: 0.7532    \n",
      "Epoch 50/60\n",
      "8161/8161 [==============================] - 96s - loss: 0.7567    \n",
      "Epoch 51/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7586    \n",
      "Epoch 52/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7501    \n",
      "Epoch 53/60\n",
      "8161/8161 [==============================] - 105s - loss: 0.7484   \n",
      "Epoch 54/60\n",
      "8161/8161 [==============================] - 95s - loss: 0.7584    \n",
      "Epoch 55/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7493    \n",
      "Epoch 56/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7483    \n",
      "Epoch 57/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7485    \n",
      "Epoch 58/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7514    \n",
      "Epoch 59/60\n",
      "8161/8161 [==============================] - 94s - loss: 0.7503    \n",
      "Epoch 60/60\n",
      "2300/8161 [=======>......................] - ETA: 91s - loss: 0.7827"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=10, epochs=60)\n",
    "\n",
    "# Save model\n",
    "#model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('future_60_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    decoded_sentence = []\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    for idk in range(0, 10):\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        decoded_sentence.append(output_tokens)\n",
    "        target_seq = output_tokens\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n",
    "# for seq_index in range(100):\n",
    "#     # Take one sequence (part of the training test)\n",
    "#     # for trying out decoding.\n",
    "#     input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    \n",
    "#     start = time.time()\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     timespent  = time.time() - start\n",
    "#     print('TIME SPENT IS ', timespent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 10, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.01694915 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01694915 0.         ... 0.         0.         0.        ]] 1.0\n"
     ]
    }
   ],
   "source": [
    "tp = try_output_data[0][0].reshape((64, 64))\n",
    "print(tp, np.max(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 1.070703\n"
     ]
    }
   ],
   "source": [
    "tp = decoded_sentence[0][0].reshape((64, 64))\n",
    "print(tp, np.max(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 4096)\n",
      "(1, 10, 4096)\n",
      "decoded_sentence shape  (10, 1, 1, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranjal/.local/lib/python3.5/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "image_index = 80\n",
    "try_input_data  = encoder_input_data[image_index, 0:10, :]\n",
    "try_output_data = decoder_target_data[image_index, 0:10, :]\n",
    "\n",
    "try_output_data = np.expand_dims(try_output_data, axis=0)\n",
    "try_input_data  = np.expand_dims(try_input_data, axis=0)\n",
    "print(try_input_data.shape)\n",
    "print(try_output_data.shape)\n",
    "\n",
    "\n",
    "input_seq = try_input_data#encoder_input_data[seq_index: seq_index + 1]\n",
    "decoded_sentence = decode_sequence(try_input_data)\n",
    "decoded_sentence = np.array(decoded_sentence)\n",
    "print('decoded_sentence shape ', decoded_sentence.shape)\n",
    "#print(decoded_sentence[0], len(decoded_sentence))\n",
    "# endtime = time.time()\n",
    "# timespent  = endtime - start\n",
    "# print(start, endtime)\n",
    "# print (time.localtime( start ))\n",
    "# print (time.localtime( endtime ))\n",
    "# print(timespent)\n",
    "\n",
    "\n",
    "for i in range(decoded_sentence.shape[0]):\n",
    "    img  = decoded_sentence[i][0][0]\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(0.64,0.64)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "#     values = np.sort( img )\n",
    "#     vmin = values[ +int( len(values)*0.01 ) ]\n",
    "#     idx = -int( len(values)*0.01 )\n",
    "#     if idx>=0:\n",
    "#         idx = -1\n",
    "#     vmax = values[idx]\n",
    "    img = img.reshape(64, 64)\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    #print(vmin, vmax, img.shape)\n",
    "    ax.imshow(img, vmin=0, vmax=1, cmap=mpl.cm.jet)\n",
    "    outfile = '/home/pranjal/finalresult/'+str(image_index)+'_'+str(i)+'.png'\n",
    "    time.sleep(0.5)\n",
    "    fig.savefig(outfile)\n",
    "    \n",
    "    img  = try_output_data[0][i]\n",
    "    #img = img.reshape(64, 64)\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(0.64,0.64)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "#     values = np.sort( img )\n",
    "#     vmin = values[ +int( len(values)*0.01 ) ]\n",
    "#     idx = -int( len(values)*0.01 )\n",
    "#     if idx>=0:\n",
    "#         idx = -1\n",
    "#     vmax = values[idx]\n",
    "    img = img.reshape(64, 64)\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    ax.imshow(img, vmin=0, vmax=1, cmap=mpl.cm.jet)\n",
    "    outfile = '/home/pranjal/finalresult/real_'+str(image_index)+'_'+str(i)+'.png'\n",
    "    time.sleep(0.5)\n",
    "    fig.savefig(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the loss function\n",
    "y_pred = K.constant([[ 1, 1, 1, 1], \n",
    "                     [ 1, 1, 1, 3],\n",
    "                     [ 1, 1, 1, 3],\n",
    "                     [ 1, 1, 1, 3],\n",
    "                     [ 1, 1, 1, 3],\n",
    "                     [ 1, 1, 1, 3]])\n",
    "y_true = K.constant([[ 1, 1, 1, 1],\n",
    "                     [ 1, 1, 1, 1],\n",
    "                     [-1, 1, 1, 1],\n",
    "                     [-1,-1, 1, 1],\n",
    "                     [-1,-1,-1, 1],\n",
    "                     [-1,-1,-1,-1]])\n",
    "\n",
    "true = K.eval(y_true)\n",
    "pred = K.eval(y_pred)\n",
    "loss = K.eval(my_loss(y_true, y_pred))\n",
    "\n",
    "for i in range(true.shape[0]):\n",
    "    print(true[i], pred[i], loss[i], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp  = []\n",
    "max_a = []\n",
    "min_a = []\n",
    "\n",
    "for k in images_list:\n",
    "    temp = images_list[k]\n",
    "    image_index = 0\n",
    "    tmp  = np.array(temp)\n",
    "    vmin = np.min(tmp)\n",
    "    vmax = np.max(tmp)\n",
    "    for img in temp:\n",
    "        fig = plt.figure(frameon=False)\n",
    "        fig.set_size_inches(0.64,0.64)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        ax.imshow(img, vmin=vmin, vmax=vmax, cmap=mpl.cm.jet)\n",
    "        outfile = '/home/pranjal/testimages_real2/'+str(image_index)+'_'+str(i)+'_test1.png'\n",
    "        fig.savefig(outfile)\n",
    "        image_index = image_index+1\n",
    "    \n",
    "    #temp = np.array(temp)\n",
    "    #max_a.append(np.max(temp))\n",
    "    #min_a.append(np.min(temp))\n",
    "\n",
    "#min_a = np.array(min_a)\n",
    "#max_a = np.array(max_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
