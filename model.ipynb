{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/'\n",
    "allfiles = glob.glob(path+'sensory/tile/*.npy')\n",
    "sali = glob.glob(path+'content/saliencyImages/*.npy')\n",
    "motion = glob.glob(path+'content/motionImages/*.npy')\n",
    "prob = glob.glob(path+'sensory/tileProb/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/'\n",
    "allfiles = glob.glob(path+'sensory/tile/*.npy')\n",
    "sali = glob.glob(path+'content/saliencyImages/*.npy')\n",
    "motion = glob.glob(path+'content/motionImages/*.npy')\n",
    "prob = glob.glob(path)\n",
    "\n",
    "def myGenerator():\n",
    "    while True:\n",
    "        index_list = random.sample(range(1, 30000), 10)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            f = allfiles[i]\n",
    "            s = f.split('_')\n",
    "            saliFile = '../datasets/content/saliencyImages/'+s[0][25:]+'_saliency_'+s[2].split('.')[0]+'.npy'\n",
    "            motionFile = '../datasets/content/motionImages/'+s[0][25:]+'_motion_'+s[2].split('.')[0]+'.npy'\n",
    "            probFile = '../datasets/sensory/tileProb/'+s[0][25:]+'_user'+s[1][4:]+'_'+s[2].split('.')[0]+'.npy'\n",
    "            a = np.load(f)\n",
    "            b = np.load(saliFile)\n",
    "            c = np.load(motionFile)\n",
    "            d = [a, b, c]\n",
    "            alldata_x.append(d)\n",
    "            alldata_y.append(np.load(probFile))\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_x = np.rollaxis(alldata_x, 1, 5)  \n",
    "        #alldata_x = alldata_x.reshape((32, 30, 240, 480, 3))\n",
    "        #alldata_x = np.swapaxes(alldata_x, 1, 4)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        yield alldata_x, alldata_y\n",
    "# x = myGenerator()\n",
    "# xtrain, ytrain = next(x)\n",
    "# print('xtrain shape:',xtrain.shape)\n",
    "# print('ytrain shape:',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8534c8f28>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADKCAYAAACrHYtRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGSFJREFUeJzt3X2MHPd93/H3d2b24fYeeSTvSPFBFB3aBv0kJYwlwwGqWggsC07Voqlgo6jVQCj7hwI4gItEaoHG7V/uH43roK0RFTEsA45txXErwVXjSrSVwG70ZImWRUmUaJESjyGP5D3xeA97uzPf/jFz1PJ4vAfe7e3d3OcFLG7mt7O7v/3d3udmfzO/35i7IyIi+RW0ugIiItJcCnoRkZxT0IuI5JyCXkQk5xT0IiI5p6AXEcm5pgW9md1tZsfN7ISZPdSs1xERkYVZM86jN7MQeBP4bWAAeAH4vLu/tuovJiIiC2rWHv3HgRPu/ra7zwDfBe5t0muJiMgCoiY97y7gdMP6AHD79TYuWsnLtDepKiIi+TTOyEV3377Yds0K+kWZ2WHgMECZCrfbXa2qiojIhvS0f/+dpWzXrK6bM8CehvXdWdkV7v6Iux9y90MFSk2qhoiINCvoXwAOmNktZlYEPgc80aTXEhGRBTSl68bd62b2+8CPgBD4hrsfa8ZriYjIwprWR+/uTwJPNuv5RURkaTQyVkQk5xT0IiI5p6AXEck5Bb2ISM4p6EVEck5BLyKScwp6EZGcU9CLiOScgl5EJOcU9CIiOaegFxHJOQW9iEjOKehFRHJOQS8iknMKehGRnFPQi4jknIJeRCTnFPQiIjmnoBcRyTkFvYhIzinoRURyTkEvIpJzCnoRkZxT0IuI5JyCXkQk56JWV0BEZL2xUgkLQ5LJSQhCAIJyCSAt22BWFPRmdgoYB2Kg7u6HzKwX+B6wDzgF3OfuIyurpojIGjADd7xaxWeLChHVOz9CvT0Eh/LwDIVj70K9DkAyNQ2J47WZ1tV7EauxR/8P3f1iw/pDwBF3/4qZPZSt/9EqvI6ISHNZQLi1B9xJLl3GazN4tUppaJqwWqTaW2BqW5HxTx8gmnY8NCqDVQrnxknefhev18B98ddZY83ourkXuDNbfhR4BgW9iKwRKxSxYgEO3ExSjvAwIByfxmLHT55euOsliYkvDqV79hYQ7ejHOypM9rVhCYTTCcFMQvfPBohHRgnayvhMDfbcxMUv/Ab1duPy3oRw2iiNGB7AjuenCP7m5TmVtPn/IVyvfIXMV/CkZnYSGAEc+DN3f8TMRt29J7vfgJHZ9evpsl6/3e664XqIiFyR9albIcKrVTAj7N2CFQrEO7fhpZBguo5NTGPjE8RDI3gcQxIv+rxR3zaSvi1M7e4kKRgeGh1vjhFMTFHb0UPh1CDeUWH8I9u5vDNk7DereC2g3DONv97BniPThP/vGB7HWBhCYGkdb9DT/v2fu/uhxbZb6R79b7n7GTPrA54yszca73R3N7N5/5OY2WHgMECZygqrISKSyQLbq+8Fdzw0nC6cG0w3medh4YH9eFsRD0MIjWB0AkbG8Knp9FtAElM/NwjnBim90vBygJdK+K4txDu2Mn1TBYudzoE63ScD4nJAra2dS/uM6a1FLj58iOrWhGD7NEk9YNuREt2npim+fYH6mbNEe3dRP/XuqjbJivbor3oisy8Dl4F/Bdzp7mfNbCfwjLt/YKHHao9eRNabaOcO6jf3EZcjosszBGOTxG+9vejjgvZ2bPdOxg9upeOtMbwccep3upjpjek4GVJvg+I4RFPO1HbDDo1R/L9dxG1GecgpjidU/tfzaRdOEIIn1+3OWeoe/Q0HvZm1A4G7j2fLTwH/EbgLGGo4GNvr7n+40HMp6EUkd4Lwut1BViox+s9uY7IvoNYBHaedvmf+ntpNW5jeVmRsf0S9DHv+eoyZrWUKR14CC655vrXouukH/mfaDU8E/IW7/7WZvQA8ZmYPAO8A963gNURE1l6aazd+YNQs3ROfG/ZBmPbNAz3HximOtxOXAix2xj/aj4dGabhG/7NVwqkaZ+7qYarf2f+0gy9yDGEBNxz07v428LF5yodI9+pFRDamlXZpzz5+bjgnMT4b/Edfo/JakbBvO8mWDqZ2d1IrBVy6uUT3r6YgSdj9+Fm8Upr3mMJyaGSsiEgrZAOz6gNnYABKrzil7PTKoL2doG8b0/u34QbhP7iNcKKGTdfx428ve3CWgl5E8mWl3S5rrbGe2XIyMUFycoLi4AWsWKD24VuY7msjLgeEez9GcayG/ezokl9CQb+JWaG4rodti9yI2UFO3lYkqRRJooCgnpBEAeF0Hasn6Tn0tTrJ+YskU1PzHuhcD5LJSZiE4KdHKTWUhwf2s5zaKug3GzMsKlD/5IcJ547WE8kBTxJsegaCgOjSJFRnoFwi6W4nbitAKcI7ipiD7eghiQKi0WnswjDxhSEsDNf9DtBSTvNspKDfZIKPfIDkl8cpvj5AvFG+2oosQzx4/pqyoFIhqMewtYu4rUDh0jQ2PJb2k09PY+UySX8vtic9bx5I/xHECVaNCUcvU39nYF3u9S+Fgj7vGufOMCN55Q3CA/sZ/ngf3d++9g9CJDcaPvvJ5GTaDXIaDPD2dqyzA+9sJ9m5DavFBJcmSS4MUZwt766QFEK8UiCpbGHmYB+l//1Ca9/TDVLQ59ncCZLcsds+xLk7uuh79lI6DWuTJlESabkFPtfJ5CTJxAScywoKRdi9Ew7cTK29SDQ6RXjmIjZ2Cfbvxaoz2M/eXnAQ1HqmoM+5oFLB2srU378HLwYEf/My218GSiWC9vb0w75BP7wi88pmnrzuZ3r2rJzZn4DXZqiffCctBuKGHSA7/jYUonT7Dfp3oqDPM3esrYxPTWPPvoJlH9ywv4+3vvQ+3vfYOJN726n84DkgnaMj6OqkfvbcQs8qsvqyEaOrchDUFxlFupRvsA3beG0mnd1yA1PQ58V1umDioeH35tbu38bkrXuxesKBR4ehOkPnidPEpKekjX1yH53Hx0BBL/OwQpGgqwOA5NLltDAwLIqwQholXqtnV1xaWjDOThwWjlexiSkA4rODK5q6N9q5g3jHVqp9bVjsBHUnqCWQONHwBMQxjE/glyfSfvulBP8G3ZOfpaDPi+t8WIP2dqytTHxxCK/XaXv2TbxWh3KJeGiYoFJh5u7fZKQ/YuvPR0hefWPe55HNJbj1IGfu6sHqQAAkMNOd3VeDLW/G1MvG6PsDZm6ZxicibCYAIOpPL+wRhk4cG/5uO5ZAcdQojjrRFHQOzBBN1KiZEb19FrZtIemo4IUQ6+lId05CIy5HeBQQVGPCqRrB4DDJpfH3Lh4yz+e+fvYcnD1HEa7s5FgYpv+MburHyyXi/m5qHRFxOSAuBRTH6pSGpgnGJuHCEMnE1Lo/xXI5Vm2a4pXQ7JXLsNCovyAkKJewtvKVbeOh4ev+E7BSifCmHSSDFzbkBY+liRq/Ia7kGM4ij71q0N4dH6XWUWBsf5GpfqPy905cNmqdMNWfUBwJKI2CxbD12DTVLQXaT10mmKlDdQarx3ipSG1HJ9ELx2/8Mx2EhL09+O5+Lu/vpNZmFC8ndD7/bjof/TrIzFlNn6Z4NSnoV8nsQSjPpkBq/N0u5ewanYHTHBttSP46ZIVi2k/uCVYsEuzdRdJdobq1TFwO8NBIQsCM7pcG052cEydXp82DkHD7Vnz8cjqKdh39HtfqClPSIlYoAlz99XKhg1DLPAAlq0jtumKNn3OvVq+MDC02bBPt20uSdfvU+7qIRnrT67+uVBLPOwhrI1HQbyRByNTv/MaV1bhodPzlc1ipRNBWhm29ANT7u7G/++WGP4CUB2FPd/p7McPb0y615OhrLa5VPjVefs/eYllzweSdgn4j8YS2x5+/trhaJa5WYXQMADvBVecIyyqbM9oYSLsTerqhpwsvRSSVIm5G7E50ajDt2xVpEQX9RrKULoDZg1/qLliZOf3qViql53l/4BbC0cswXcXb2yAM8bYiwdAlvKudeleZwrlROPHulYOB9Va9B5GMgj5HglsPMnVTO6UnN+Z8HC03z8HooL2doLMD7+4kqZTwUkhtRw/mTjBdJxi6BEMj1LOzmwwFu6w/CvocSY6+Rmnp1yKQudyv2ZNPJiayOVHe63qZ7RRLspvIehe0ugIi64p7Pru9FjtmY3b1HDCNt7nPcb2yuc8h64b26EVWU2PAzR3HMLdsLS32uvNczu6628y37dzHLPd9agxHUynoRVbTYiG5iKBSATOCrk68o0K9r4uJm0pc+KdTxLWQpBpS6qqSJMa/+djTnJ3poTea4O9G97OzPMbRkd30t40TmHN790k+3fEaXx74LL84dxPHPvFtvnVpG19761MMn+tmx49DJncEFC45bcMJ0WTMTHfE8AcDoimodToeQlxyOk8GBHdfpBAm7O4cZSaJODncS/WNbkofHKNajaiNlLG2mL6+MTpLVU7/dA/lIdj12K/weh3f3Y9NzVyZa4Z6neTyRDqvjTtWKGKFCCsWIIpg65Yrx0WSKO18KIxMYZcm8Jn0eXxqOr14SBynZfpnMa/NNzJ2dpa8ei0dRQrpSNJ10A6SMw3T5QaVCrx/H0k5YqanxPiuiNK4M7XVqG4xcJjZ4nS/BSSkc8NcTgiyI7sDdydU3ilQvugUJp32s7X0QtHTCeF0TPTGu+lo0OHRK59vKxYJOjuuHjS0lOkMgjD9ucA0v0GlciVgAcLeLVAuwXSVpL+XuK2AFwMm+4p0PnEUr9UJt3TjO/vw7ApO4/s76Pj+C0T926FUxEfHiMcuXf9vMXtdayvju/sB8NnTW91xM6ZvqlD52ZvE2anGeacpEJYiCAnayulkR6USFgQQRXipAKUitS1t1LoLlAenIHbO397Fjp9cuLKX4WYEtRirJ5AkEKT/OKwWU+9pW/Aq7dG+vemCGV4s4IXoyhETD0MILb26TTEgidKJl0r/50X9Q1qnrFQi7NtOfC4dQen12vJ+V4uF61pqnM99uV0q8/XNX29ajsWeqlDEigWsXGLmI/uILs/AL95cftvmmKZAWIokTs+oaNTwwQ6AkhlEBawQsf3o1HvXWQ1CgkIEiWNdHRBFWHYwyms1omrXgiPzfHQs/Xo6+7KNH9zp9KtsaHZl+td4dCwNg4Xm2ZaW8WqV+umBhTeaLwRnf+/rIeBnNU6lsdxAnXf7q89Numois4WeqjaTbjcxQfjMsK6ItgKbO+jnM89BpSsfOHjvq28S49X0jyEeGr72eRaZY+NGvlpaGOLrKRA2EzOsmM6sYmFI0L+deGsnwdgkNj6xtJGvmzWg5rzvFU3/u1nbcIUWDXoz+wbwWeC8u384K+sFvgfsA04B97n7iJkZ8DXgHmAS+Jfu/lJzqt4iLQzaPM2PvVGEH/oAtW0V3Cz91hU7hZEpfKaGv/iq5lORDWEpe/TfBP4r8K2GsoeAI+7+FTN7KFv/I+AzwIHsdjvw9eynyIYQ9vfh23uJu8vU20ImOyPaT08QjE7A6CUAfGoar2v8q2wciwa9u/+tme2bU3wvcGe2/CjwDGnQ3wt8y9MjvM+aWY+Z7XT3s6tVYZFmigfPw+B5DChkN2fOTIhB+N7BRZEN4EZHxvY3hPc5oD9b3gWcbthuICu7hpkdNrMXzezFGjd+fUiRNadJ42SDWfEUCNne+7I/9e7+iLsfcvdDBUorrYaIiFzHjQb9oJntBMh+zl5+5Qywp2G73VmZiIi0yI0G/RPA/dny/cDjDeVfsNQdwJj651eflUpYKf0WFPb3aQIpEVnQUk6v/A7pgddtZjYA/DHwFeAxM3sAeAe4L9v8SdJTK0+Qnl75e02o86YX9HRDVwfeXqbWUSS4MARoGgcRmd9Szrr5/HXuumbOgqy//sGVVmrTmh16TjY4Krvq/dwAjwfPY8OjeG1G80yLyKI0MnYNWalE8Gv70pV6dsJekga5xVmgV2fwWg3IRtxeZy/d67U1qLGI5IGCfg15tUp87PgqPZm6aURkafTNX0Qk5xT0IiI5p6AXEck5Bb2ISM4p6EVEck5BLyKScwp6EZGcU9CLiOScgr5VgpBoz26ifXtbXRMRyTmNjG2VJKY+cAaLCq2uiYjknPboW8ldc9aISNMp6FtNc9aISJMp6DeiIGx1DURkA1HQb0BR/3aCSiW9ypSuLiUii9DB2A2ofvZcq6sgIhuI9uhFRHJOQS8iknMKehGRnFPQi4jknIJeRCTnFPQiIjmnoBcRyTkFvYhIzinoRURybtGgN7NvmNl5M3u1oezLZnbGzI5mt3sa7nvYzE6Y2XEz+3SzKi4iIkuzlD36bwJ3z1P+VXe/Nbs9CWBmB4HPAR/KHvPfzUwzcImItNCiQe/ufwsML/H57gW+6+5Vdz8JnAA+voL6iYjICq2kj/73zeyVrGtnS1a2CzjdsM1AVnYNMztsZi+a2Ys1qiuohoiILORGg/7rwPuAW4GzwH9e7hO4+yPufsjdDxUo3WA1RERkMTcU9O4+6O6xuyfA/+C97pkzwJ6GTXdnZSIi0iI3FPRmtrNh9Z8As2fkPAF8zsxKZnYLcAB4fmVVFBGRlVj0wiNm9h3gTmCbmQ0AfwzcaWa3Ag6cAv41gLsfM7PHgNeAOvCgu8fNqbqIiCyF+Tq4OHWX9frtdlerqyEisqE87d//ubsfWmw7jYwVEck5Bb2ISM4p6EVEck5BLyKScwp6EZGcU9CLiOScgl5EJOcU9CIiOaegFxHJOQW9iEjOKehFRHJOQS8iknMKehGRnFPQi4jknIJeRCTnFPQiIjmnoBcRyTkFvYhIzinoRURyTkEvIpJzCnoRkZxT0IuI5JyCXkQk5xT0IiI5p6AXEck5Bb2ISM4tGvRmtsfMfmJmr5nZMTP7Ylbea2ZPmdlb2c8tWbmZ2Z+a2Qkze8XMfr3Zb0JERK5vKXv0deBL7n4QuAN40MwOAg8BR9z9AHAkWwf4DHAgux0Gvr7qtRYRkSVbNOjd/ay7v5QtjwOvA7uAe4FHs80eBf5xtnwv8C1PPQv0mNnOVa+5iIgsybL66M1sH3Ab8BzQ7+5ns7vOAf3Z8i7gdMPDBrKyuc912MxeNLMXa1SXWW0REVmqJQe9mXUAfwX8gbtfarzP3R3w5bywuz/i7ofc/VCB0nIeKiIiy7CkoDezAmnIf9vdf5AVD852yWQ/z2flZ4A9DQ/fnZWJiEgLLOWsGwP+HHjd3f+k4a4ngPuz5fuBxxvKv5CdfXMHMNbQxSMiImssWsI2nwT+BfBLMzualf1b4CvAY2b2APAOcF9235PAPcAJYBL4vVWtsYiILMuiQe/uPwXsOnffNc/2Djy4wnqJiMgq0chYEZGcU9CLiOScgl5EJOcU9CIiOaegFxHJOQW9iEjOKehFRHJOQS8iknMKehGRnFPQi4jknIJeRCTnFPQiIjmnoBcRyTkFvYhIzinoRURyTkEvIpJzCnoRkZxT0IuI5JyCXkQk5xT0IiI5p6AXEck5Bb2ISM6Zu7e6DpjZBWACuNjquqwz21CbzEftMj+1y/zy3C43u/v2xTZaF0EPYGYvuvuhVtdjPVGbzE/tMj+1y/zULuq6ERHJPQW9iEjOraegf6TVFViH1CbzU7vMT+0yv03fLuumj15ERJpjPe3Ri4hIE7Q86M3sbjM7bmYnzOyhVtdnLZnZN8zsvJm92lDWa2ZPmdlb2c8tWbmZ2Z9m7fSKmf1662rePGa2x8x+YmavmdkxM/tiVr7Z26VsZs+b2S+ydvkPWfktZvZc9v6/Z2bFrLyUrZ/I7t/Xyvo3m5mFZvaymf0wW1e7NGhp0JtZCPw34DPAQeDzZnawlXVaY98E7p5T9hBwxN0PAEeydUjb6EB2Owx8fY3quNbqwJfc/SBwB/Bg9pnY7O1SBT7l7h8DbgXuNrM7gP8EfNXdfw0YAR7Itn8AGMnKv5ptl2dfBF5vWFe7NHL3lt2ATwA/alh/GHi4lXVqQRvsA15tWD8O7MyWdwLHs+U/Az4/33Z5vgGPA7+tdrmqTSrAS8DtpAOBoqz8yt8T8CPgE9lylG1nra57k9pjN+k//08BPwRM7XL1rdVdN7uA0w3rA1nZZtbv7mez5XNAf7a86doq+1p9G/AcapfZ7omjwHngKeBXwKi717NNGt/7lXbJ7h8Dtq5tjdfMfwH+EEiy9a2oXa7S6qCXBXi627EpT4sysw7gr4A/cPdLjfdt1nZx99jdbyXdg/048MEWV6nlzOyzwHl3/3mr67KetTrozwB7GtZ3Z2Wb2aCZ7QTIfp7PyjdNW5lZgTTkv+3uP8iKN327zHL3UeAnpF0SPWYWZXc1vvcr7ZLd3w0MrXFV18IngX9kZqeA75J233wNtctVWh30LwAHsiPkReBzwBMtrlOrPQHcny3fT9pHPVv+hewskzuAsYaujNwwMwP+HHjd3f+k4a7N3i7bzawnW24jPW7xOmng/2622dx2mW2v3wV+nH0TyhV3f9jdd7v7PtL8+LG7/3M2ebtco9UHCYB7gDdJ+xv/Xavrs8bv/TvAWaBG2o/4AGl/4RHgLeBpoDfb1kjPUPoV8EvgUKvr36Q2+S3SbplXgKPZ7R61Cx8FXs7a5VXg32fl+4HngRPAXwKlrLycrZ/I7t/f6vewBm10J/BDtcu1N42MFRHJuVZ33YiISJMp6EVEck5BLyKScwp6EZGcU9CLiOScgl5EJOcU9CIiOaegFxHJuf8PwX0JQ6205YcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8b35fb828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xtrain[0, 0][:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/sensory/tile/landscape_user09_54.npy\n",
      "['../datasets/sensory/tile/landscape', 'user09', '54.npy']\n",
      "../datasets/sensory/tileProb/landscape_user09_54.npy\n"
     ]
    }
   ],
   "source": [
    "print(allfiles[1])\n",
    "f = allfiles[1]\n",
    "s = f.split('_')\n",
    "print(s)\n",
    "print('../datasets/sensory/tileProb/'+s[0][25:]+'_user'+s[1][4:]+'_'+s[2].split('.')[0]+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/'\n",
    "videoNames = os.listdir(path+'content/saliency/')\n",
    "videoNames = [i[:-13] for i in videoNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the numpy arrays from saliency, motion maps and sensor data\n",
    "sali = glob.glob(path+'content/saliencyImages/*.npy')\n",
    "motion = glob.glob(path+'content/motionImages/*.npy')\n",
    "sensory = glob.glob(path+'sensory/tile/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "input_shape=(30, 240, 480, 3)\n",
    "def mySegNet(input_shape):\n",
    "    base_model  = MobileNet(input_shape=(224,224,3), include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    model = Sequential();\n",
    "    model.add(TimeDistributed(cnn_model, input_shape=input_shape))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "    model.add(LSTM(200, return_sequences=True))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "    \n",
    "\n",
    "#mySegNet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., steps_per_epoch=5, epochs=5, use_multiprocessing=True)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "input_shape=(30, 240, 480, 3)\n",
    "model = mySegNet(input_shape)\n",
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=5, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model  = VGG16(input_shape=(224,224,3), include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "cnn_model = Model(inputs=base_model.input, outputs=x)\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['landscape', 'pacman', 'panel', 'ride', 'sport']\n",
      "(150, 1920, 3840)\n"
     ]
    }
   ],
   "source": [
    "videoNames = sorted(videoNames)[5:]\n",
    "print(videoNames)\n",
    "#print(sorted(sali))\n",
    "\n",
    "for video in videoNames:\n",
    "    npys = [s for s in sali if video in s]\n",
    "    for npy in npys:\n",
    "        data = np.load(npy)\n",
    "        print(data.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pre-trained VGG model\n",
    "def loadVGG16Model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    #print (\"Model loaded..!\")\n",
    "    #print (base_model.summary())\n",
    "    return base_model\n",
    "vgg_model = loadVGG16Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f4ae05e9a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getBaseModel():\n",
    "    #base_model  = MobileNet(input_shape=(224,224,3), include_top=False)\n",
    "    #base_model  = ResNet50(input_shape=(224,224,3), include_top=False)\n",
    "    base_model  = VGG16(input_shape=(224,224,3), include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    sgd = optimizers.SGD(lr=0.0001)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    print (model.summary())\n",
    "    return model\n",
    "getBaseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(): \n",
    "    nFilters=32\n",
    "    kernelSize=(3,3)\n",
    "    poolSize=(2,2)\n",
    "    batchSize=64\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(40, (3, 3), activation='relu'), input_shape=[224, 224, 1]))\n",
    "    #model.add(TimeDistributed(Conv2D(nFilters, kernel_size = kernelSize, activation=\"relu\"), input_shape=[1920, 3840,1]))\n",
    "    model.add(TimeDistributed(Conv2D(nFilters*2, kernel_size = kernelSize, activation=\"relu\")))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=poolSize)))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(nFilters, kernel_size = kernelSize, activation=\"relu\")))\n",
    "    model.add(TimeDistributed(Conv2D(nFilters*2, kernel_size = kernelSize, activation=\"relu\")))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=poolSize)))\n",
    "\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(5))\n",
    "    #model.add(Dense(, input_dim=, activation='relu'))\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "model = buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
