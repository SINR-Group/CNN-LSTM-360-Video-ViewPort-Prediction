{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 120\n",
    "width = 240\n",
    "path = '../datasets/'\n",
    "allfiles = glob.glob(path+'sensory/tile/*.npy')\n",
    "sali = glob.glob(path+'content/saliencyImages/*.npy')\n",
    "motion = glob.glob(path+'content/motionImages/*.npy')\n",
    "prob = glob.glob(path+'sensory/tileProb/*.npy')\n",
    "\n",
    "def myGenerator():\n",
    "    while True:\n",
    "        index_list = random.sample(range(1, 23999), 3)\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            f = allfiles[i]\n",
    "            s = f.split('_')\n",
    "            saliFile = '../datasets/content/saliencyImages/'+s[0][25:]+'_saliency_'+s[2].split('.')[0]+'.npy'\n",
    "            motionFile = '../datasets/content/motionImages/'+s[0][25:]+'_motion_'+s[2].split('.')[0]+'.npy'\n",
    "            probFile = '../datasets/sensory/tileProb/'+s[0][25:]+'_user'+s[1][4:]+'_'+s[2].split('.')[0]+'.npy'\n",
    "            a = np.load(f)\n",
    "            b = np.load(saliFile)\n",
    "            c = np.load(motionFile)\n",
    "            d = [a, b, c]\n",
    "            alldata_x.append(d)\n",
    "            alldata_y.append(np.load(probFile))\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_x = np.rollaxis(alldata_x, 1, 5)  \n",
    "        #alldata_x = alldata_x.reshape((32, 30, height, width, 3))\n",
    "        #alldata_x = np.swapaxes(alldata_x, 1, 4)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        yield alldata_x, alldata_y\n",
    "# x = myGenerator()\n",
    "# xtrain, ytrain = next(x)\n",
    "# print('xtrain shape:',xtrain.shape)\n",
    "# print('ytrain shape:',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 188s 626ms/step - loss: 0.1467\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1473\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1443\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1432\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 174s 581ms/step - loss: 0.1420\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1400\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1398\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1399\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1362\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 175s 582ms/step - loss: 0.1382\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1381\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1341\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1353\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1347\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1306\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1369\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1341\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 174s 581ms/step - loss: 0.1334\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 174s 581ms/step - loss: 0.1327\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1287\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 176s 588ms/step - loss: 0.1330\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1332\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1284\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1298\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1290\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1344\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1353\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1249\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1302\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1283\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1211\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1262\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1251\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1267\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1264\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1237\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1260\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1237\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1271\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1252\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1269\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1289\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1265\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1260\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1299\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1238\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1251\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1271\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1283\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1212\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1279\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1271\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1264\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1293\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1251\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1254\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1224\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1219\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1234\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1276\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1251\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 175s 583ms/step - loss: 0.1191\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1214\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1225\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1236\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1241\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1230\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1269\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1213\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1243\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1220\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1241\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1218\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1190\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1236\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1220\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1248\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1187\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1215\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1245\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1217\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1223\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 175s 584ms/step - loss: 0.1225\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1194\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1204\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1204\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1229\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1244\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1228\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1215\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1190\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1213\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1254\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 176s 585ms/step - loss: 0.1172\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1188\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1237\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 175s 585ms/step - loss: 0.1215\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1166\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 176s 586ms/step - loss: 0.1208\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 176s 587ms/step - loss: 0.1073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the numpy arrays from saliency, motion maps and sensor data\n",
    "sali = glob.glob(path+'content/saliencyImages/*.npy')\n",
    "motion = glob.glob(path+'content/motionImages/*.npy')\n",
    "sensory = glob.glob(path+'sensory/tile/*.npy')\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "input_shape=(30, height, width, 3)\n",
    "def mySegNet(input_shape):\n",
    "    base_model  = MobileNet(input_shape=(224,224,3), include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    model = Sequential();\n",
    "    model.add(TimeDistributed(cnn_model, input_shape=input_shape))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "    model.add(LSTM(200, return_sequences=True))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "    \n",
    "input_shape=(30, height, width, 3)\n",
    "model = mySegNet(input_shape)\n",
    "\n",
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=300, epochs=100)\n",
    "model.save('model1.h5')\n",
    "model.save_weights('model_weights1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.1071\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.1117\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.1134\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.1057\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 168s 558ms/step - loss: 0.1036\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.1098\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.1048\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.1061\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.1042\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.1074\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.1091\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.1030\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.1016\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.1036\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.1017\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.1012\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.1011\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 167s 556ms/step - loss: 0.1006\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.1008\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.1024\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 166s 555ms/step - loss: 0.1011\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 167s 555ms/step - loss: 0.1006\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.1013\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0988\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.1007\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0978\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0972\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0971\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 166s 553ms/step - loss: 0.0986\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 165s 550ms/step - loss: 0.0971\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 167s 555ms/step - loss: 0.0989\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0960\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 167s 556ms/step - loss: 0.1008\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 171s 571ms/step - loss: 0.0996\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0982\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0965\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0937\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0750\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0453\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 170s 566ms/step - loss: 0.0367\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 166s 552ms/step - loss: 0.0331\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 165s 550ms/step - loss: 0.0286\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0260\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 165s 551ms/step - loss: 0.0257\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0234\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0219\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0219\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0208\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0192\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0207\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0189\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0188\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0175\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0177\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0182\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0175\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.0165\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0168\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0157\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0165\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0166\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0154\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0156\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 170s 566ms/step - loss: 0.0156\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 167s 556ms/step - loss: 0.0152\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0150\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0149\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0153\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 167s 556ms/step - loss: 0.0149\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0142\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 170s 567ms/step - loss: 0.0150\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0144\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0146\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0138\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.0141\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0138\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0141\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0139\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0142\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 168s 558ms/step - loss: 0.0135\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0133\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0136\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0131\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0134\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0133\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0123\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.0132\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0127\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0135\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0128\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 167s 557ms/step - loss: 0.0125\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 168s 558ms/step - loss: 0.0124\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0130\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 167s 558ms/step - loss: 0.0130\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 166s 554ms/step - loss: 0.0128\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0123\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0128\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0126\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0124\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0125\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=300, epochs=100)\n",
    "model.save('model2.h5')\n",
    "model.save_weights('model_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 170s 566ms/step - loss: 0.0126\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 170s 565ms/step - loss: 0.0121\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0129\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0122\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0124\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0120\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0118\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0118\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0127\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0116\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0116\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0126\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0123\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0117\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0121\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0121\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0120\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0117\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0116\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 168s 558ms/step - loss: 0.0114\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 168s 562ms/step - loss: 0.0119\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0119\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0115\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0116\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0116\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0115\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0120\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0111\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0119\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 170s 566ms/step - loss: 0.0113\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0110\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0113\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0121\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0115\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0113\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0115\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0113\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0113\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0113\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0113\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 169s 565ms/step - loss: 0.0111\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0112\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0112\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0112\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0112\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0110\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0113\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0108\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0109\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0111\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0112\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0110\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 170s 566ms/step - loss: 0.0108\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0111\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0112\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0108\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0109\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0118\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0107\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 169s 564ms/step - loss: 0.0109\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0110\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0105\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0108\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0110\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 170s 566ms/step - loss: 0.0106\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0106\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0108\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 167s 556ms/step - loss: 0.0115\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0104\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0106\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0108\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0104\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0108\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0108\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0107\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 168s 562ms/step - loss: 0.0106\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0106\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0105\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0110\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0106\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0105\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0106\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0104\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0105\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0103\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0103\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0108\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 168s 559ms/step - loss: 0.0106\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0104\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0107\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0104\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0104\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 169s 563ms/step - loss: 0.0105\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0105\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0103\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 0.0105\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0102\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 168s 560ms/step - loss: 0.0104\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0108\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 168s 561ms/step - loss: 0.0102\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=myGenerator(),\n",
    "                    use_multiprocessing=True,\n",
    "                   steps_per_epoch=300, epochs=100)\n",
    "model.save('model3.h5')\n",
    "model.save_weights('model_weights3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "batchSize = 3\n",
    "allfiles = glob.glob('../datasets/testData/sens/*.npy')\n",
    "def myTestDataGenerator():\n",
    "    global count\n",
    "    while True:\n",
    "        index_list = range(count, count+batchSize)\n",
    "        count += batchSize\n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        for i in index_list:\n",
    "            f = allfiles[i]\n",
    "            s = f.split('_')\n",
    "            saliFile = '../datasets/content/saliencyImages/'+s[0][25:]+'_saliency_'+s[2].split('.')[0]+'.npy'\n",
    "            motionFile = '../datasets/content/motionImages/'+s[0][25:]+'_motion_'+s[2].split('.')[0]+'.npy'\n",
    "            probFile = '../datasets/sensory/tileProb/'+s[0][25:]+'_user'+s[1][4:]+'_'+s[2].split('.')[0]+'.npy'\n",
    "            a = np.load(f)\n",
    "            b = np.load(saliFile)\n",
    "            c = np.load(motionFile)\n",
    "            d = [a, b, c]\n",
    "            alldata_x.append(d)\n",
    "            alldata_y.append(np.load(probFile))\n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_x = np.rollaxis(alldata_x, 1, 5)  \n",
    "        #alldata_x = alldata_x.reshape((32, 30, height, width, 3))\n",
    "        #alldata_x = np.swapaxes(alldata_x, 1, 4)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        yield alldata_x, alldata_y\n",
    "# x = myTestDataGenerator()\n",
    "# xtest, ytest = next(x)\n",
    "# print('xtrain shape:',xtest.shape)\n",
    "# print('ytrain shape:',ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape:  (3, 30, 200)\n",
      "predictions shape:  (6, 30, 200)\n",
      "predictions shape:  (9, 30, 200)\n",
      "predictions shape:  (12, 30, 200)\n",
      "predictions shape:  (15, 30, 200)\n",
      "predictions shape:  (18, 30, 200)\n",
      "predictions shape:  (21, 30, 200)\n",
      "predictions shape:  (24, 30, 200)\n",
      "predictions shape:  (27, 30, 200)\n",
      "predictions shape:  (30, 30, 200)\n",
      "predictions shape:  (33, 30, 200)\n",
      "predictions shape:  (36, 30, 200)\n",
      "predictions shape:  (39, 30, 200)\n",
      "predictions shape:  (42, 30, 200)\n",
      "predictions shape:  (45, 30, 200)\n",
      "predictions shape:  (48, 30, 200)\n",
      "predictions shape:  (51, 30, 200)\n",
      "predictions shape:  (54, 30, 200)\n",
      "predictions shape:  (57, 30, 200)\n",
      "predictions shape:  (60, 30, 200)\n",
      "predictions shape:  (63, 30, 200)\n",
      "predictions shape:  (66, 30, 200)\n",
      "predictions shape:  (69, 30, 200)\n",
      "predictions shape:  (72, 30, 200)\n",
      "predictions shape:  (75, 30, 200)\n",
      "predictions shape:  (78, 30, 200)\n",
      "predictions shape:  (81, 30, 200)\n",
      "predictions shape:  (84, 30, 200)\n",
      "predictions shape:  (87, 30, 200)\n",
      "predictions shape:  (90, 30, 200)\n",
      "predictions shape:  (93, 30, 200)\n",
      "predictions shape:  (96, 30, 200)\n",
      "predictions shape:  (99, 30, 200)\n",
      "predictions shape:  (102, 30, 200)\n",
      "predictions shape:  (105, 30, 200)\n",
      "predictions shape:  (108, 30, 200)\n",
      "predictions shape:  (111, 30, 200)\n",
      "predictions shape:  (114, 30, 200)\n",
      "predictions shape:  (117, 30, 200)\n",
      "predictions shape:  (120, 30, 200)\n",
      "predictions shape:  (123, 30, 200)\n",
      "predictions shape:  (126, 30, 200)\n",
      "predictions shape:  (129, 30, 200)\n",
      "predictions shape:  (132, 30, 200)\n",
      "predictions shape:  (135, 30, 200)\n",
      "predictions shape:  (138, 30, 200)\n",
      "predictions shape:  (141, 30, 200)\n",
      "predictions shape:  (144, 30, 200)\n",
      "predictions shape:  (147, 30, 200)\n",
      "predictions shape:  (150, 30, 200)\n",
      "predictions shape:  (153, 30, 200)\n",
      "predictions shape:  (156, 30, 200)\n",
      "predictions shape:  (159, 30, 200)\n",
      "predictions shape:  (162, 30, 200)\n",
      "predictions shape:  (165, 30, 200)\n",
      "predictions shape:  (168, 30, 200)\n",
      "predictions shape:  (171, 30, 200)\n",
      "predictions shape:  (174, 30, 200)\n",
      "predictions shape:  (177, 30, 200)\n",
      "predictions shape:  (180, 30, 200)\n",
      "predictions shape:  (183, 30, 200)\n",
      "predictions shape:  (186, 30, 200)\n",
      "predictions shape:  (189, 30, 200)\n",
      "predictions shape:  (192, 30, 200)\n",
      "predictions shape:  (195, 30, 200)\n",
      "predictions shape:  (198, 30, 200)\n",
      "predictions shape:  (201, 30, 200)\n",
      "predictions shape:  (204, 30, 200)\n",
      "predictions shape:  (207, 30, 200)\n",
      "predictions shape:  (210, 30, 200)\n",
      "predictions shape:  (213, 30, 200)\n",
      "predictions shape:  (216, 30, 200)\n",
      "predictions shape:  (219, 30, 200)\n",
      "predictions shape:  (222, 30, 200)\n",
      "predictions shape:  (225, 30, 200)\n",
      "predictions shape:  (228, 30, 200)\n",
      "predictions shape:  (231, 30, 200)\n",
      "predictions shape:  (234, 30, 200)\n",
      "predictions shape:  (237, 30, 200)\n",
      "predictions shape:  (240, 30, 200)\n",
      "predictions shape:  (243, 30, 200)\n",
      "predictions shape:  (246, 30, 200)\n",
      "predictions shape:  (249, 30, 200)\n",
      "predictions shape:  (252, 30, 200)\n",
      "predictions shape:  (255, 30, 200)\n",
      "predictions shape:  (258, 30, 200)\n",
      "predictions shape:  (261, 30, 200)\n",
      "predictions shape:  (264, 30, 200)\n",
      "predictions shape:  (267, 30, 200)\n",
      "predictions shape:  (270, 30, 200)\n",
      "predictions shape:  (273, 30, 200)\n",
      "predictions shape:  (276, 30, 200)\n",
      "predictions shape:  (279, 30, 200)\n",
      "predictions shape:  (282, 30, 200)\n",
      "predictions shape:  (285, 30, 200)\n",
      "predictions shape:  (288, 30, 200)\n",
      "predictions shape:  (291, 30, 200)\n",
      "predictions shape:  (294, 30, 200)\n",
      "predictions shape:  (297, 30, 200)\n",
      "predictions shape:  (300, 30, 200)\n",
      "predictions shape:  (303, 30, 200)\n",
      "predictions shape:  (306, 30, 200)\n",
      "predictions shape:  (309, 30, 200)\n",
      "predictions shape:  (312, 30, 200)\n",
      "predictions shape:  (315, 30, 200)\n",
      "predictions shape:  (318, 30, 200)\n",
      "predictions shape:  (321, 30, 200)\n",
      "predictions shape:  (324, 30, 200)\n",
      "predictions shape:  (327, 30, 200)\n",
      "predictions shape:  (330, 30, 200)\n",
      "predictions shape:  (333, 30, 200)\n",
      "predictions shape:  (336, 30, 200)\n",
      "predictions shape:  (339, 30, 200)\n",
      "predictions shape:  (342, 30, 200)\n",
      "predictions shape:  (345, 30, 200)\n",
      "predictions shape:  (348, 30, 200)\n",
      "predictions shape:  (351, 30, 200)\n",
      "predictions shape:  (354, 30, 200)\n",
      "predictions shape:  (357, 30, 200)\n",
      "predictions shape:  (360, 30, 200)\n",
      "predictions shape:  (363, 30, 200)\n",
      "predictions shape:  (366, 30, 200)\n",
      "predictions shape:  (369, 30, 200)\n",
      "predictions shape:  (372, 30, 200)\n",
      "predictions shape:  (375, 30, 200)\n",
      "predictions shape:  (378, 30, 200)\n",
      "predictions shape:  (381, 30, 200)\n",
      "predictions shape:  (384, 30, 200)\n",
      "predictions shape:  (387, 30, 200)\n",
      "predictions shape:  (390, 30, 200)\n",
      "predictions shape:  (393, 30, 200)\n",
      "predictions shape:  (396, 30, 200)\n",
      "predictions shape:  (399, 30, 200)\n",
      "predictions shape:  (402, 30, 200)\n",
      "predictions shape:  (405, 30, 200)\n",
      "predictions shape:  (408, 30, 200)\n",
      "predictions shape:  (411, 30, 200)\n",
      "predictions shape:  (414, 30, 200)\n",
      "predictions shape:  (417, 30, 200)\n",
      "predictions shape:  (420, 30, 200)\n",
      "predictions shape:  (423, 30, 200)\n",
      "predictions shape:  (426, 30, 200)\n",
      "predictions shape:  (429, 30, 200)\n",
      "predictions shape:  (432, 30, 200)\n",
      "predictions shape:  (435, 30, 200)\n",
      "predictions shape:  (438, 30, 200)\n",
      "predictions shape:  (441, 30, 200)\n",
      "predictions shape:  (444, 30, 200)\n",
      "predictions shape:  (447, 30, 200)\n",
      "predictions shape:  (450, 30, 200)\n",
      "predictions shape:  (453, 30, 200)\n",
      "predictions shape:  (456, 30, 200)\n",
      "predictions shape:  (459, 30, 200)\n",
      "predictions shape:  (462, 30, 200)\n",
      "predictions shape:  (465, 30, 200)\n",
      "predictions shape:  (468, 30, 200)\n",
      "predictions shape:  (471, 30, 200)\n",
      "predictions shape:  (474, 30, 200)\n",
      "predictions shape:  (477, 30, 200)\n",
      "predictions shape:  (480, 30, 200)\n",
      "predictions shape:  (483, 30, 200)\n",
      "predictions shape:  (486, 30, 200)\n",
      "predictions shape:  (489, 30, 200)\n",
      "predictions shape:  (492, 30, 200)\n",
      "predictions shape:  (495, 30, 200)\n",
      "predictions shape:  (498, 30, 200)\n",
      "predictions shape:  (501, 30, 200)\n",
      "predictions shape:  (504, 30, 200)\n",
      "predictions shape:  (507, 30, 200)\n",
      "predictions shape:  (510, 30, 200)\n",
      "predictions shape:  (513, 30, 200)\n",
      "predictions shape:  (516, 30, 200)\n",
      "predictions shape:  (519, 30, 200)\n",
      "predictions shape:  (522, 30, 200)\n",
      "predictions shape:  (525, 30, 200)\n",
      "predictions shape:  (528, 30, 200)\n",
      "predictions shape:  (531, 30, 200)\n",
      "predictions shape:  (534, 30, 200)\n",
      "predictions shape:  (537, 30, 200)\n",
      "predictions shape:  (540, 30, 200)\n",
      "predictions shape:  (543, 30, 200)\n",
      "predictions shape:  (546, 30, 200)\n",
      "predictions shape:  (549, 30, 200)\n",
      "predictions shape:  (552, 30, 200)\n",
      "predictions shape:  (555, 30, 200)\n",
      "predictions shape:  (558, 30, 200)\n",
      "predictions shape:  (561, 30, 200)\n",
      "predictions shape:  (564, 30, 200)\n",
      "predictions shape:  (567, 30, 200)\n",
      "predictions shape:  (570, 30, 200)\n",
      "predictions shape:  (573, 30, 200)\n",
      "predictions shape:  (576, 30, 200)\n",
      "predictions shape:  (579, 30, 200)\n",
      "predictions shape:  (582, 30, 200)\n",
      "predictions shape:  (585, 30, 200)\n",
      "predictions shape:  (588, 30, 200)\n",
      "predictions shape:  (591, 30, 200)\n",
      "predictions shape:  (594, 30, 200)\n",
      "predictions shape:  (597, 30, 200)\n",
      "predictions shape:  (600, 30, 200)\n",
      "predictions shape:  (603, 30, 200)\n",
      "predictions shape:  (606, 30, 200)\n",
      "predictions shape:  (609, 30, 200)\n",
      "predictions shape:  (612, 30, 200)\n",
      "predictions shape:  (615, 30, 200)\n",
      "predictions shape:  (618, 30, 200)\n",
      "predictions shape:  (621, 30, 200)\n",
      "predictions shape:  (624, 30, 200)\n",
      "predictions shape:  (627, 30, 200)\n",
      "predictions shape:  (630, 30, 200)\n",
      "predictions shape:  (633, 30, 200)\n",
      "predictions shape:  (636, 30, 200)\n",
      "predictions shape:  (639, 30, 200)\n",
      "predictions shape:  (642, 30, 200)\n",
      "predictions shape:  (645, 30, 200)\n",
      "predictions shape:  (648, 30, 200)\n",
      "predictions shape:  (651, 30, 200)\n",
      "predictions shape:  (654, 30, 200)\n",
      "predictions shape:  (657, 30, 200)\n",
      "predictions shape:  (660, 30, 200)\n",
      "predictions shape:  (663, 30, 200)\n",
      "predictions shape:  (666, 30, 200)\n",
      "predictions shape:  (669, 30, 200)\n",
      "predictions shape:  (672, 30, 200)\n",
      "predictions shape:  (675, 30, 200)\n",
      "predictions shape:  (678, 30, 200)\n",
      "predictions shape:  (681, 30, 200)\n",
      "predictions shape:  (684, 30, 200)\n",
      "predictions shape:  (687, 30, 200)\n",
      "predictions shape:  (690, 30, 200)\n",
      "predictions shape:  (693, 30, 200)\n",
      "predictions shape:  (696, 30, 200)\n",
      "predictions shape:  (699, 30, 200)\n",
      "predictions shape:  (702, 30, 200)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-26394ef70e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalTestSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyTestDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-c1b3abd9925b>\u001b[0m in \u001b[0;36mmyTestDataGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mmotionFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../datasets/content/motionImages/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_motion_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprobFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../datasets/sensory/tileProb/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_user'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaliFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotionFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 421\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_weights('model_weights1.h5')\n",
    "totalTestSamples = len(allfiles)\n",
    "predictions = []\n",
    "for i in range(0, totalTestSamples, batchSize):\n",
    "    x = myTestDataGenerator()\n",
    "    xtest, ytest = next(x)\n",
    "    pred = model.predict(xtest, batch_size=batchSize)\n",
    "    for p in pred:\n",
    "        predictions.append(p)\n",
    "print('predictions shape: ', np.array(predictions).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index  = 28\n",
    "thresh = 0.5\n",
    "\n",
    "temp = predictions[0][index] \n",
    "temp[temp > thresh] = 1\n",
    "temp[temp <= thresh] = 0\n",
    "\n",
    "for i, j in enumerate(ytest[0][index]):\n",
    "    if ytest[0][index][i] != temp[i]:\n",
    "        print('Index: ', i, 'Value: ', ytest[0][index][i], temp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ytest[0][index].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
